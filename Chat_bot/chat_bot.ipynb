{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6a27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3f4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseMessage contains all Human,Ai,System and tool message\n",
    "from langgraph.graph import add_messages\n",
    "class chat_state(TypedDict):\n",
    "    messages:Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614a242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinanant\\AppData\\Local\\Temp\\ipykernel_19176\\2160552625.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model=ChatOllama(model='llama2')\n"
     ]
    }
   ],
   "source": [
    "model=ChatOllama(model='llama2')\n",
    "\n",
    "def chat_node(state:chat_state):\n",
    "    messages=state['messages']\n",
    "    result=model.invoke(messages)\n",
    "    return {'messages':[result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a711b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer=MemorySaver()\n",
    "graph=StateGraph(chat_state)\n",
    "\n",
    "graph.add_node('chat_node',chat_node)\n",
    "\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "chatbot=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d300458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb7272bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: HI,MY NAME IS ANANT SINGH\n",
      "AI: \n",
      "Nice to meet you, Anant Singh! *smiles* How are you today?\n",
      "User: WHAT IS MY NAME?\n",
      "AI: \n",
      "Your name is Anant Singh.\n",
      "User: 2+3=?\n",
      "AI: \n",
      "2 + 3 = 5.\n",
      "User: WHAT IS 3 + PREVIOUS RESULT\n",
      "AI: \n",
      "The previous result was 5, so 3 + 5 = 8.\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "thread_id='1'\n",
    "\n",
    "while True:\n",
    "    user_msg=input('Type here: ')\n",
    "    print('User:',user_msg)\n",
    "    if user_msg.strip().lower() in ['exit','quit','bye']:\n",
    "        break\n",
    "    config={'configurable':{'thread_id':thread_id}}\n",
    "    result=chatbot.invoke({'messages':[HumanMessage(content=user_msg)]},config=config)\n",
    "    \n",
    "    print('AI:',result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7708339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='HI,MY NAME IS ANANT SINGH', additional_kwargs={}, response_metadata={}, id='989ec1a0-e661-4cb1-8971-8fd7006b3a83'), AIMessage(content='\\nNice to meet you, Anant Singh! *smiles* How are you today?', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-07-25T17:08:41.5014106Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7442514000, 'load_duration': 2855228200, 'prompt_eval_count': 30, 'prompt_eval_duration': 2282612300, 'eval_count': 21, 'eval_duration': 2303276000, 'model_name': 'llama2'}, id='run--0c8cfa0e-982e-49a7-ab85-69a34362fa37-0', usage_metadata={'input_tokens': 30, 'output_tokens': 21, 'total_tokens': 51}), HumanMessage(content='WHAT IS MY NAME?', additional_kwargs={}, response_metadata={}, id='6de4c861-ba21-4fa7-830b-2bcf40ed1fbf'), AIMessage(content='\\nYour name is Anant Singh.', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-07-25T17:08:51.4050215Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2230483500, 'load_duration': 7488000, 'prompt_eval_count': 75, 'prompt_eval_duration': 1385943000, 'eval_count': 9, 'eval_duration': 835283100, 'model_name': 'llama2'}, id='run--2f805951-3511-4a84-aa01-c0a8b5c01818-0', usage_metadata={'input_tokens': 75, 'output_tokens': 9, 'total_tokens': 84}), HumanMessage(content='2+3=?', additional_kwargs={}, response_metadata={}, id='7f35530b-206c-4d9f-9ced-fc50c5848b72'), AIMessage(content='\\n2 + 3 = 5.', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-07-25T17:09:02.7644755Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2226039400, 'load_duration': 8946200, 'prompt_eval_count': 106, 'prompt_eval_duration': 1257812200, 'eval_count': 10, 'eval_duration': 957907200, 'model_name': 'llama2'}, id='run--73c3b89c-e65b-4d84-bf79-4f62eaea2747-0', usage_metadata={'input_tokens': 106, 'output_tokens': 10, 'total_tokens': 116}), HumanMessage(content='WHAT IS 3 + PREVIOUS RESULT', additional_kwargs={}, response_metadata={}, id='e31ec38f-92e0-460e-9fb4-1868401b0797'), AIMessage(content='\\nThe previous result was 5, so 3 + 5 = 8.', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-07-25T17:09:23.3020315Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3915801400, 'load_duration': 13915400, 'prompt_eval_count': 147, 'prompt_eval_duration': 1940361900, 'eval_count': 19, 'eval_duration': 1951244000, 'model_name': 'llama2'}, id='run--cd9b9fa3-3748-4124-8fc6-b80b2f7f50ba-0', usage_metadata={'input_tokens': 147, 'output_tokens': 19, 'total_tokens': 166})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0697a1-c77e-627a-800a-65629282ed65'}}, metadata={'source': 'loop', 'step': 10, 'parents': {}, 'thread_id': '1'}, created_at='2025-07-25T17:09:23.303077+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0697a1-a21e-6ea1-8009-e826304881d3'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349998c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
